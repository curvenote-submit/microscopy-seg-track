@article{article,
 author = {Hochreiter, Sepp},
 month = {4},
 title = {Untersuchungen zu dynamischen neuronalen {Netzen}},
 year = {1991}
}

@article{azimiAdvancedSteelMicrostructural2018,
 author = {Azimi, Seyed Majid and Britz, Dominik and Engstler, Michael and Fritz, Mario and M{\" u}cklich, Frank},
 doi = {10.1038/s41598-018-20037-5},
 issn = {2045-2322},
 journal = {Scientific Reports},
 month = {feb 1},
 note = {[Online; accessed 2024-05-17]},
 number = {1},
 pages = {2128},
 title = {Advanced {Steel} {Microstructural} {Classification} by {Deep} {Learning} {Methods}},
 url = {https://www.nature.com/articles/s41598-018-20037-5},
 volume = {8},
 year = {2018}
}

@misc{baiMaskedAutoencodersEnable2022,
 author = {Bai, Yutong and Wang, Zeyu and Xiao, Junfei and Wei, Chen and Wang, Huiyu and Yuille, Alan and Zhou, Yuyin and Xie, Cihang},
 doi = {10.48550/arXiv.2208.12256},
 month = {nov 9},
 note = {Masked Distillers [EfficientSAM]},
 title = {Masked {Autoencoders} {Enable} {Efficient} {Knowledge} {Distillers}},
 url = {http://arxiv.org/abs/2208.12256},
 year = {2022}
}

@book{bishopPatternRecognitionMachine2006,
 address = {New York},
 author = {Bishop, Christopher M.},
 issn = {978-0-387-31073-2},
 publisher = {Springer},
 series = {Information {Science} and {Statistics}},
 title = {Pattern {Recognition} and {Machine} {Learning}},
 year = {2006}
}

@misc{caoSwinUnetUnetlikePure2021,
 author = {Cao, Hu and Wang, Yueyue and Chen, Joy and Jiang, Dongsheng and Zhang, Xiaopeng and Tian, Qi and Wang, Manning},
 doi = {10.48550/arXiv.2105.05537},
 month = {may 12},
 note = {Comment: a drafted manuscript},
 title = {Swin-{Unet}: Unet-like {Pure} {Transformer} for {Medical} {Image} {Segmentation}},
 url = {http://arxiv.org/abs/2105.05537},
 year = {2021}
}

@misc{chengSegmentTrackAnything2023,
 author = {Cheng, Yangming and Li, Liulei and Xu, Yuanyou and Li, Xiaodi and Yang, Zongxin and Wang, Wenguan and Yang, Yi},
 doi = {10.48550/arXiv.2305.06558},
 month = {may 11},
 note = {SAM+DeAOTSAM-Track \textbackslash{}par https://mp.weixin.qq.com/s/H5GvPU-JHkL5OwwwUkI9hA},
 title = {Segment and {Track} {Anything}},
 url = {http://arxiv.org/abs/2305.06558},
 year = {2023}
}

@inproceedings{chuangObjectiveEvaluationSegmentation2010,
 author = {Chuang, Hsiao-Chiang and Comer, Mary L.},
 booktitle = {2010 {IEEE} {Southwest} {Symposium} on {Image} {Analysis} \& {Interpretation} ({SSIAI})},
 doi = {10.1109/SSIAI.2010.5483898},
 month = {5},
 note = {[Online; accessed 2024-05-18]},
 pages = {137--140},
 title = {Objective {Evaluation} for {Segmentation} of {Microscope} {Images} of {Materials}},
 url = {https://ieeexplore.ieee.org/document/5483898},
 year = {2010}
}

@article{congReviewYOLOObject2023,
 author = {Cong, Xiaohan and Li, Shixin and Chen, Fankai and Liu, Chen and Meng, Yue},
 doi = {10.54097/fcis.v4i2.9730},
 issn = {2832-6024},
 journal = {Frontiers in Computing and Intelligent Systems},
 month = {jun 25},
 note = {YOLO2},
 number = {2},
 pages = {17--20},
 title = {A {Review} of {YOLO} {Object} {Detection} {Algorithms} {Based} on {Deep} {Learning}},
 url = {https://drpress.org/ojs/index.php/fcis/article/view/9730},
 volume = {4},
 year = {2023}
}

@article{dosovitskiyIMAGEWORTH16X162021,
 author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
 doi = {10.48550/arXiv.2010.11929},
 pages = {22},
 title = {AN {IMAGE} {IS} {WORTH} 16X16 {WORDS}: TRANSFORMERS {FOR} {IMAGE} {RECOGNITION} {AT} {SCALE}},
 year = {2021}
}

@inproceedings{freixenetAnotherSurveyImage2002,
 address = {Berlin, Heidelberg},
 author = {Freixenet, J. and Mu{\~ n}oz, X. and Raba, D. and Mart{\' i}, J. and Cuf{\' i}, X.},
 booktitle = {Computer {Vision} --- {ECCV} 2002},
 doi = {10.1007/3-540-47977-5_27},
 editor = {Heyden, Anders and Sparr, Gunnar and Nielsen, Mads and Johansen, Peter},
 issn = {978-3-540-47977-2},
 organization = {Springer},
 pages = {408--422},
 title = {Yet {Another} {Survey} on {Image} {Segmentation}: Region and {Boundary} {Information} {Integration}},
 year = {2002}
}

@article{geDeepLearningAnalysis2020,
 author = {Ge, M. and Su, F. and Zhao, Z. and Su, D.},
 doi = {10.1016/j.mtnano.2020.100087},
 issn = {2588-8420},
 journal = {Materials Today Nano},
 month = {aug 1},
 note = {1},
 pages = {100087},
 title = {Deep {Learning} {Analysis} on {Microscopic} {Imaging} in {Materials} {Science}},
 url = {https://www.sciencedirect.com/science/article/pii/S258884202030016X},
 volume = {11},
 year = {2020}
}

@article{ghoshUnderstandingDeepLearning2019,
 author = {Ghosh, Swarnendu and Das, Nibaran and Das, Ishita and Maulik, Ujjwal},
 doi = {10.1145/3329784},
 issn = {0360-0300},
 journal = {ACM Comput. Surv.},
 month = {aug 30},
 note = {},
 number = {4},
 pages = {73:1--73:35},
 title = {Understanding {Deep} {Learning} {Techniques} for {Image} {Segmentation}},
 url = {https://doi.org/10.1145/3329784},
 volume = {52},
 year = {2019}
}

@misc{guEfficientlyModelingLong2022,
 author = {Gu, Albert and Goel, Karan and R{\' e}, Christopher},
 doi = {10.48550/arXiv.2111.00396},
 month = {aug 5},
 note = {Comment: ICLR 2022 (Outstanding Paper HM)},
 title = {Efficiently {Modeling} {Long} {Sequences} with {Structured} {State} {Spaces}},
 url = {http://arxiv.org/abs/2111.00396},
 year = {2022}
}

@misc{guMambaLinearTimeSequence2023,
 author = {Gu, Albert and Dao, Tri},
 doi = {10.48550/arXiv.2312.00752},
 month = {dec 1},
 note = {[Online; accessed 2024-05-13]},
 title = {Mamba: Linear-{Time} {Sequence} {Modeling} with {Selective} {State} {Spaces}},
 url = {http://arxiv.org/abs/2312.00752},
 year = {2023}
}

@misc{heMaskedAutoencodersAre2021,
 author = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\' a}r, Piotr and Girshick, Ross},
 doi = {10.48550/arXiv.2111.06377},
 month = {dec 19},
 note = {Masked Autoencoders [EfficientSAM]},
 title = {Masked {Autoencoders} {Are} {Scalable} {Vision} {Learners}},
 url = {http://arxiv.org/abs/2111.06377},
 year = {2021}
}

@article{hintonReducingDimensionalityData2006,
 author = {Hinton, G. E. and Salakhutdinov, R. R.},
 doi = {10.1126/science.1127647},
 journal = {Science},
 month = {jul 28},
 note = {[Online; accessed 2024-05-19]},
 number = {5786},
 pages = {504--507},
 title = {Reducing the {Dimensionality} of {Data} with {Neural} {Networks}},
 url = {https://www.science.org/doi/10.1126/science.1127647},
 volume = {313},
 year = {2006}
}

@article{horwathUnderstandingImportantFeatures2020a,
 author = {Horwath, James P. and Zakharov, Dmitri N. and M{\' e}gret, R{\' e}mi and Stach, Eric A.},
 doi = {10.1038/s41524-020-00363-x},
 issn = {2057-3960},
 journal = {npj Computational Materials},
 month = {jul 29},
 note = {[Online; accessed 2024-05-16]},
 number = {1},
 pages = {1--9},
 title = {Understanding {Important} {Features} of {Deep} {Learning} {Models} for {Segmentation} of {High}-{Resolution} {Transmission} {Electron} {Microscopy} {Images}},
 url = {https://www.nature.com/articles/s41524-020-00363-x},
 volume = {6},
 year = {2020}
}

@inproceedings{kirillovSegmentAnything2023,
 author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollar, Piotr and Girshick, Ross},
 doi = {10.48550/arXiv.2304.02643},
 note = {[Online; accessed 2024-04-15]},
 pages = {4015--4026},
 title = {Segment {Anything}},
 url = {https://openaccess.thecvf.com/content/ICCV2023/html/Kirillov_Segment_Anything_ICCV_2023_paper.html},
 year = {2023}
}

@article{kramerNonlinearPrincipalComponent1991,
 author = {Kramer, Mark A.},
 doi = {10.1002/aic.690370209},
 issn = {1547-5905},
 journal = {AIChE Journal},
 note = {[Online; accessed 2024-05-19]},
 number = {2},
 pages = {233--243},
 title = {Nonlinear {Principal} {Component} {Analysis} {Using} {Autoassociative} {Neural} {Networks}},
 url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aic.690370209},
 volume = {37},
 year = {1991}
}

@misc{laiLISAReasoningSegmentation2024,
 author = {Lai, Xin and Tian, Zhuotao and Chen, Yukang and Li, Yanwei and Yuan, Yuhui and Liu, Shu and Jia, Jiaya},
 doi = {10.48550/arXiv.2308.00692},
 month = {may 1},
 note = {Comment: Code, models, and data are available at https://github.com/dvlab-research/LISA},
 title = {LISA: Reasoning {Segmentation} via {Large} {Language} {Model}},
 url = {http://arxiv.org/abs/2308.00692},
 year = {2024}
}

@article{lecunBackpropagationAppliedHandwritten1989,
 author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
 doi = {10.1162/neco.1989.1.4.541},
 issn = {0899-7667},
 journal = {Neural Computation},
 month = {12},
 note = {[Online; accessed 2024-05-19]},
 number = {4},
 pages = {541--551},
 title = {Backpropagation {Applied} to {Handwritten} {Zip} {Code} {Recognition}},
 url = {https://ieeexplore.ieee.org/abstract/document/6795724},
 volume = {1},
 year = {1989}
}

@article{lecunGradientbasedLearningApplied1998,
 author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
 doi = {10.1109/5.726791},
 issn = {1558-2256},
 journal = {Proceedings of the IEEE},
 month = {11},
 note = {},
 number = {11},
 pages = {2278--2324},
 title = {Gradient-{Based} {Learning} {Applied} to {Document} {Recognition}},
 url = {https://ieeexplore.ieee.org/document/726791},
 volume = {86},
 year = {1998}
}

@misc{liuSwinTransformerHierarchical2021,
 author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
 doi = {10.48550/arXiv.2103.14030},
 month = {aug 17},
 note = {Swin Transformer},
 title = {Swin {Transformer}: Hierarchical {Vision} {Transformer} {Using} {Shifted} {Windows}},
 url = {http://arxiv.org/abs/2103.14030},
 year = {2021}
}

@misc{liuVisionMambaComprehensive2024,
 author = {Liu, Xiao and Zhang, Chenxu and Zhang, Lei},
 doi = {10.48550/arXiv.2405.04404},
 month = {may 7},
 note = {Comment: https://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy},
 title = {Vision {Mamba}: A {Comprehensive} {Survey} and {Taxonomy}},
 url = {http://arxiv.org/abs/2405.04404},
 year = {2024}
}

@misc{liVisualizingLossLandscape2018,
 author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
 doi = {10.48550/arXiv.1712.09913},
 month = {nov 7},
 note = {Comment: NIPS 2018 (extended version, 10.5 pages), code is available at https://github.com/tomgoldstein/loss-landscape},
 title = {Visualizing the {Loss} {Landscape} of {Neural} {Nets}},
 url = {http://arxiv.org/abs/1712.09913},
 year = {2018}
}

@article{Masubuchi2020Deep,
 author = {Masubuchi, Satoru and Watanabe, Eisuke and Seo, Yuta and Okazaki, Shota and Sasagawa, Takao and Watanabe, Kenji and Taniguchi, Takashi and Machida, Tomoki},
 doi = {10.1038/s41699-020-0137-z},
 issn = {2397-7132},
 journal = {npj 2D Materials and Applications},
 month = {mar 23},
 number = {1},
 title = {Deep-learning-based image segmentation integrated with optical microscopy for automatically searching for two-dimensional materials},
 url = {http://dx.doi.org/10.1038/s41699-020-0137-z},
 volume = {4},
 year = {2020}
}

@article{mccullochLogicalCalculusIdeas1943,
 author = {McCulloch, Warren S. and Pitts, Walter},
 doi = {10.1007/BF02478259},
 issn = {1522-9602},
 journal = {The bulletin of mathematical biophysics},
 month = {dec 1},
 note = {[Online; accessed 2024-05-19]},
 number = {4},
 pages = {115--133},
 title = {A {Logical} {Calculus} of the {Ideas} {Immanent} in {Nervous} {Activity}},
 url = {https://doi.org/10.1007/BF02478259},
 volume = {5},
 year = {1943}
}

@article{minaeeImageSegmentationUsing2022,
 author = {Minaee, Shervin and Boykov, Yuri and Porikli, Fatih and Plaza, Antonio and Kehtarnavaz, Nasser and Terzopoulos, Demetri},
 doi = {10.1109/TPAMI.2021.3059968},
 issn = {1939-3539},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 month = {7},
 note = {[Online; accessed 2024-05-16]},
 number = {7},
 pages = {3523--3542},
 title = {Image {Segmentation} {Using} {Deep} {Learning}: A {Survey}},
 url = {https://ieeexplore.ieee.org/document/9356353},
 volume = {44},
 year = {2022}
}

@inproceedings{nielsenRegionMergingStatistical2003,
 author = {Nielsen, F. and Nock, R.},
 booktitle = {2003 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, 2003. {Proceedings}.},
 doi = {10.1109/CVPR.2003.1211447},
 month = {6},
 note = {[Online; accessed 2024-05-17]},
 pages = {II--19},
 title = {On {Region} {Merging}: The {Statistical} {Soundness} of {Fast} {Sorting}, with {Applications}},
 url = {https://ieeexplore.ieee.org/document/1211447},
 volume = {2},
 year = {2003}
}

@inproceedings{ramezaniAutomatic2DMaterial2023,
 author = {Ramezani, Fereshteh and Parvez, Sheikh and Fix, J. Pierce and Battaglin, Arthur and Whyte, Seamus and Borys, Nicholas J. and Whitaker, Bradley},
 booktitle = {AI and {Optical} {Data} {Sciences} {IV}},
 doi = {10.1117/12.2647425},
 month = {mar 15},
 note = {[Online; accessed 2024-05-16]},
 organization = {SPIE},
 pages = {316--322},
 title = {Automatic 2D {Material} {Detection} in {Optical} {Images} {Using} {Deep}-{Learning}-{Based} {Computer} {Vision}},
 url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12438/1243816/Automatic-2D-material-detection-in-optical-images-using-deep-learning/10.1117/12.2647425.full},
 volume = {12438},
 year = {2023}
}

@misc{ronnebergerUNetConvolutionalNetworks2015,
 author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
 doi = {10.48550/arXiv.1505.04597},
 month = {may 18},
 note = {Comment: conditionally accepted at MICCAI 2015},
 title = {U-{Net}: Convolutional {Networks} for {Biomedical} {Image} {Segmentation}},
 url = {http://arxiv.org/abs/1505.04597},
 year = {2015}
}

@inproceedings{senthilkumaranImageSegmentationSurvey2009,
 author = {Senthilkumaran, N. and Rajesh, R.},
 booktitle = {2009 {International} {Conference} on {Advances} in {Recent} {Technologies} in {Communication} and {Computing}},
 doi = {10.1109/ARTCom.2009.219},
 month = {10},
 note = {[Online; accessed 2024-08-02]},
 pages = {844--846},
 title = {Image {Segmentation} - {A} {Survey} of {Soft} {Computing} {Approaches}},
 url = {https://ieeexplore.ieee.org/abstract/document/5328277},
 year = {2009}
}

@book{shapiroComputerVision2001a,
 address = {Upper Saddle River, NJ},
 author = {Shapiro, Linda G. and Stockman, George C.},
 issn = {978-0-13-030796-5},
 publisher = {Prentice Hall},
 title = {Computer {Vision}},
 year = {2001}
}

@misc{shuTinySAMPushingEnvelope2024,
 author = {Shu, Han and Li, Wenshuo and Tang, Yehui and Zhang, Yiman and Chen, Yihao and Li, Houqiang and Wang, Yunhe and Chen, Xinghao},
 doi = {10.48550/arXiv.2312.13789},
 month = {mar 9},
 note = {[Online; accessed 2024-05-19]},
 title = {TinySAM: Pushing the {Envelope} for {Efficient} {Segment} {Anything} {Model}},
 url = {http://arxiv.org/abs/2312.13789},
 year = {2024}
}

@misc{solawetzWhatYOLOv8Ultimate2023,
 author = {Solawetz, Jacob and {Francesco}},
 month = {jan 11},
 note = {YOLOv8 \textbackslash{}par The \textbf{https://blog.roboflow.com/guide-to-yolo-models/} series of models has become famous in the computer vision world. YOLO's fame is attributable to its considerable accuracy while maintaining a small model size. YOLO models can be trained on a single GPU, which makes it accessible to a wide range of developers. Machine learning practitioners can deploy it for low cost on edge hardware or in the cloud.\textbackslash{}\textbackslash{} YOLO(You Only Look Once) YOLO  YOLO  GPU , \textbackslash{}par YOLOv8 author, Glenn Jocher at Ultralytics, shadowed the \textbf{https://blog.roboflow.com/training-a-yolov3-object-detection-model-with-a-custom-dataset/} (a deep learning framework from Facebook). As the training in the shadow repo got better, Ultralytics eventually launched its own model: \textbf{https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/}.\textbackslash{}\textbackslash{} YOLOv8 ,Ultralytics  Glenn Jocher, PyTorch(Facebook ) YOLOv3 ,Ultralytics :YOLOv5 \textbackslash{}par YOLOv5 quickly became the world's SOTA repo given its flexible Pythonic structure. This structure allowed the community to invent new modeling improvements and quickly share them across repository with similar PyTorch methods.\textbackslash{}\textbackslash{}  Pythonic ,YOLOv5  SOTA , PyTorch  \textbackslash{}par Along with strong model fundamentals, the YOLOv5 maintainers have been committed to supporting a healthy software ecosystem around the model. They actively fix issues and push the capabilities of the repository as the community demands.\textbackslash{}\textbackslash{} ,YOLOv5  \textbackslash{}par In the last two years, various models branched off of the YOLOv5 PyTorch repository, including \textbf{https://roboflow.com/model/scaled-yolov4?ref=blog.roboflow.com}, \textbf{https://blog.roboflow.com/train-yolor-on-a-custom-dataset/}, and \textbf{https://blog.roboflow.com/yolov7-breakdown/}. Other models emerged around the world out of their own PyTorch based implementations, such as \textbf{https://blog.roboflow.com/how-to-train-yolox-on-a-custom-dataset/} and \textbf{https://blog.roboflow.com/how-to-train-yolov6-on-a-custom-dataset/}. Along the way, each YOLO model has brought new SOTA techniques that continue to push the model's accuracy and efficiency.\textbackslash{}\textbackslash{} ,YOLOv5 PyTorch , Scaled-YOLOv4YOLOR  YOLOv7 PyTorch , YOLOX  YOLOv6, YOLO  SOTA , \textbackslash{}par Over the last six months, Ultralytics worked on researching the newest SOTA version of YOLO, YOLOv8. YOLOv8 was launched on January 10th, 2023.\textbackslash{}\textbackslash{} ,Ultralytics  YOLO  SOTA  YOLOv8 YOLOv82023110},
 publisher = {Roboflow Blog},
 title = {What {Is} {YOLOv8}? {The} {Ultimate} {Guide}. [2024]},
 url = {https://blog.roboflow.com/whats-new-in-yolov8/},
 year = {2023}
}

@misc{songSAMLighteningLightweightSegment2024,
 author = {Song, Yanfei and Pu, Bangzheng and Wang, Peng and Jiang, Hongxu and Dong, Dong and Cao, Yongxiang and Shen, Yiqing},
 doi = {10.48550/arXiv.2403.09195},
 month = {mar 17},
 note = {[Online; accessed 2024-05-19]},
 title = {SAM-{Lightening}: A {Lightweight} {Segment} {Anything} {Model} with {Dilated} {Flash} {Attention} to {Achieve} 30 {Times} {Acceleration}},
 url = {http://arxiv.org/abs/2403.09195},
 year = {2024}
}

@article{sterbentzUniversalImageSegmentation2021,
 author = {Sterbentz, Randy M. and Haley, Kristine L. and Island, Joshua O.},
 doi = {10.1038/s41598-021-85159-9},
 issn = {2045-2322},
 journal = {Scientific Reports},
 month = {mar 11},
 note = {[Online; accessed 2024-05-18]},
 number = {1},
 pages = {5808},
 title = {Universal {Image} {Segmentation} for {Optical} {Identification} of 2D {Materials}},
 url = {https://www.nature.com/articles/s41598-021-85159-9},
 volume = {11},
 year = {2021}
}

@article{tobiasImageSegmentationHistogram2002,
 author = {Tobias, O.J. and Seara, R.},
 doi = {10.1109/TIP.2002.806231},
 issn = {1941-0042},
 journal = {IEEE Transactions on Image Processing},
 month = {12},
 note = {[Online; accessed 2024-08-02]},
 number = {12},
 pages = {1457--1465},
 title = {Image {Segmentation} by {Histogram} {Thresholding} {Using} {Fuzzy} {Sets}},
 url = {https://ieeexplore.ieee.org/abstract/document/1176934},
 volume = {11},
 year = {2002}
}

@misc{touvronLLaMAOpenEfficient2023,
 author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\' e}e and Rozi{\` e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
 doi = {10.48550/arXiv.2302.13971},
 month = {feb 27},
 note = {[Online; accessed 2024-05-19]},
 title = {LLaMA: Open and {Efficient} {Foundation} {Language} {Models}},
 url = {http://arxiv.org/abs/2302.13971},
 year = {2023}
}

@book{vapnikNatureStatisticalLearning1995,
 address = {New York},
 author = {Vapnik, Vladimir Naumovich},
 issn = {978-0-387-94559-0},
 publisher = {Springer},
 title = {The {Nature} of {Statistical} {Learning} {Theory}},
 year = {1995}
}

@inproceedings{vaswaniAttentionAllYou2017,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L{} and Polosukhin, Illia},
 doi = {10.48550/arXiv.1706.03762},
 booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
 note = {[Online; accessed 2024-04-15]},
 organization = {Curran Associates, Inc.},
 title = {Attention {Is} {All} {You} {Need}},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
 volume = {30},
 year = {2017}
}

@misc{vRealTimeObject2022,
 author = {V, Viswanatha and K, Chandana R. and C., Ramachandra A.},
 doi = {10.48550/arXiv.2208.00773},
 month = {jul 23},
 note = {[Online; accessed 2024-05-16]},
 title = {Real {Time} {Object} {Detection} {System} with {YOLO} and {CNN} {Models}: A {Review}},
 url = {http://arxiv.org/abs/2208.00773},
 year = {2022}
}

@misc{xiongEfficientSAMLeveragedMasked2023,
 author = {Xiong, Yunyang and Varadarajan, Bala and Wu, Lemeng and Xiang, Xiaoyu and Xiao, Fanyi and Zhu, Chenchen and Dai, Xiaoliang and Wang, Dilin and Sun, Fei and Iandola, Forrest and Krishnamoorthi, Raghuraman and Chandra, Vikas},
 doi = {10.48550/arXiv.2312.00863},
 month = {dec 1},
 note = {\textbackslash{}sectionEfficientSAMMetaSAM,5% \textbackslash{}par https://mp.weixin.qq.com/s/VqFW2mVan82B2fpcjkQ0Wg},
 title = {EfficientSAM: Leveraged {Masked} {Image} {Pretraining} for {Efficient} {Segment} {Anything}},
 url = {http://arxiv.org/abs/2312.00863},
 year = {2023}
}

@misc{xuLongShortTermTransformer2021,
 author = {Xu, Mingze and Xiong, Yuanjun and Chen, Hao and Li, Xinyu and Xia, Wei and Tu, Zhuowen and Soatto, Stefano},
 doi = {10.48550/arXiv.2107.03377},
 month = {dec 22},
 note = {Comment: NeurIPS 2021 Spotlight},
 title = {Long {Short}-{Term} {Transformer} for {Online} {Action} {Detection}},
 url = {http://arxiv.org/abs/2107.03377},
 year = {2021}
}

@misc{xuVisualMambaSurvey2024,
 author = {Xu, Rui and Yang, Shu and Wang, Yihui and Cai, Yu and Du, Bo and Chen, Hao},
 doi = {10.48550/arXiv.2404.18861},
 month = {jul 6},
 note = {Comment: Under Review},
 title = {Visual {Mamba}: A {Survey} and {New} {Outlooks}},
 url = {http://arxiv.org/abs/2404.18861},
 year = {2024}
}

@misc{yanBridgingGapEndtoend2023,
 author = {Yan, Feng and Luo, Weixin and Zhong, Yujie and Gan, Yiyang and Ma, Lin},
 doi = {10.48550/arXiv.2305.12724},
 month = {may 22},
 note = {SAM+MOTVISAM},
 title = {Bridging the {Gap} {Between} {End}-to-end and {Non}-{End}-to-end {Multi}-{Object} {Tracking}},
 url = {http://arxiv.org/abs/2305.12724},
 year = {2023}
}

@article{yangDecouplingFeaturesHierarchical2022,
 author = {Yang, Zongxin and Yang, Yi},
 doi = {10.48550/arXiv.2210.09782},
 journal = {Advances in Neural Information Processing Systems},
 month = {dec 6},
 note = {DeAOT},
 pages = {36324--36336},
 title = {Decoupling {Features} in {Hierarchical} {Propagation} for {Video} {Object} {Segmentation}},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/eb890c36af87e4ca82e8ef7bcba6a284-Abstract-Conference.html},
 volume = {35},
 year = {2022}
}

@misc{yangTrackAnythingSegment2023,
 author = {Yang, Jinyu and Gao, Mingqi and Li, Zhe and Gao, Shang and Wang, Fangjing and Zheng, Feng},
 doi = {10.48550/arXiv.2304.11968},
 month = {apr 27},
 note = { \textbackslash{}par Track Anything Model, TAMSegment Anything Model, SAM,SAM ,SAM ,\textbf{}TAM,,,, \textbackslash{}par \textbackslash{}sectionSAM+VOSTrack-Anything \textbackslash{}par https://mp.weixin.qq.com/s/Q4X3pUP07QM2TdvVE\textunderscore{}WRYg},
 title = {Track {Anything}: Segment {Anything} {Meets} {Videos}},
 url = {http://arxiv.org/abs/2304.11968},
 year = {2023}
}

@inproceedings{zhangDVISDecoupledVideo2023,
 author = {Zhang, Tao and Tian, Xingye and Wu, Yu and Ji, Shunping and Wang, Xuebo and Zhang, Yuan and Wan, Pengfei},
 doi = {10.48550/arXiv.2306.03413},
 note = {\textbackslash{}section\&DVIS \textbackslash{}par https://mp.weixin.qq.com/s/VqVuSza2IG7p1l\textunderscore{}RBjt1HQ},
 pages = {1282--1291},
 title = {DVIS: Decoupled {Video} {Instance} {Segmentation} {Framework}},
 url = {https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DVIS_Decoupled_Video_Instance_Segmentation_Framework_ICCV_2023_paper.html},
 year = {2023}
}

@misc{zhangFasterSegmentAnything2023,
 author = {Zhang, Chaoning and Han, Dongshen and Qiao, Yu and Kim, Jung Uk and Bae, Sung-Ho and Lee, Seungkyu and Hong, Choong Seon},
 doi = {10.48550/arXiv.2306.14289},
 month = {jul 1},
 note = {Comment: First work to make SAM lightweight for mobile applications},
 title = {Faster {Segment} {Anything}: Towards {Lightweight} {SAM} for {Mobile} {Applications}},
 url = {http://arxiv.org/abs/2306.14289},
 year = {2023}
}

@inproceedings{zhangResearchAdvancedImage2022,
 author = {Zhang, Yifan and Deng, Wenqing and Zheng, Kai and Lu, Xiaoyao},
 booktitle = {2022 {International} {Conference} on {Applied} {Physics} and {Computing} ({ICAPC})},
 doi = {10.1109/ICAPC57304.2022.00060},
 month = {9},
 note = {2},
 pages = {282--289},
 title = {Research {Advanced} in the {Image} {Segmentation}},
 url = {https://ieeexplore.ieee.org/document/10091316},
 year = {2022}
}

@misc{zhangSamGuidedEnhancedFineGrained2023,
 author = {Zhang, Zhenyu and Wang, Benlu and Liang, Weijie and Li, Yizhi and Guo, Xuechen and Wang, Guanhong and Li, Shiyan and Wang, Gaoang},
 doi = {10.48550/arXiv.2311.01004},
 month = {dec 30},
 note = {https://www.youtube.com/watch?v=j2qSVKit4pc},
 title = {Sam-{Guided} {Enhanced} {Fine}-{Grained} {Encoding} with {Mixed} {Semantic} {Learning} for {Medical} {Image} {Captioning}},
 url = {http://arxiv.org/abs/2311.01004},
 year = {2023}
}

@misc{zhangVMUNETV2RethinkingVision2024,
 author = {Zhang, Mingya and Yu, Yue and Gu, Limei and Lin, Tingsheng and Tao, Xianping},
 doi = {10.48550/arXiv.2403.09157},
 month = {mar 14},
 note = {Comment: 12 pages, 4 figures},
 title = {VM-{UNET}-{V2} {Rethinking} {Vision} {Mamba} {UNet} for {Medical} {Image} {Segmentation}},
 url = {http://arxiv.org/abs/2403.09157},
 year = {2024}
}

@article{zhangYOLOSeriesTarget2023,
 author = {Zhang, Yuan},
 doi = {10.54097/hset.v39i.6653},
 issn = {2791-0210},
 journal = {Highlights in Science, Engineering and Technology},
 month = {apr 1},
 note = {YOLO3},
 pages = {841--847},
 title = {YOLO {Series} {Target} {Detection} {Technology} and {Application}},
 url = {https://drpress.org/ojs/index.php/HSET/article/view/6653},
 volume = {39},
 year = {2023}
}

@misc{zhaoFastSegmentAnything2023,
 author = {Zhao, Xu and Ding, Wenchao and An, Yongqi and Du, Yinglong and Yu, Tao and Li, Min and Tang, Ming and Wang, Jinqiao},
 doi = {10.48550/arXiv.2306.12156},
 month = {jun 21},
 note = {Comment: Technical Report. The code is released at https://github.com/CASIA-IVA-Lab/FastSAM},
 title = {Fast {Segment} {Anything}},
 url = {http://arxiv.org/abs/2306.12156},
 year = {2023}
}

@article{zhuDeepLearningFrameworkAutomated2022,
 author = {Zhu, Zhiwen and Lu, Jiayi and Zheng, Fengru and Chen, Cheng and Lv, Yang and Jiang, Hao and Yan, Yuyi and Narita, Akimitsu and M{\" u}llen, Klaus and Wang, Xiao-Ye and Sun, Qiang},
 doi = {10.1002/anie.202213503},
 issn = {1521-3773},
 journal = {Angewandte Chemie International Edition},
 note = {2},
 number = {49},
 pages = {e202213503},
 title = {A {Deep}-{Learning} {Framework} for the {Automated} {Recognition} of {Molecules} in {Scanning}-{Probe}-{Microscopy} {Images}},
 url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.202213503},
 volume = {61},
 year = {2022}
}

@inproceedings{zhuSwinVoxelMorphSymmetricUnsupervised2022,
 address = {Cham},
 author = {Zhu, Yongpei and Lu, Shi},
 booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} -- {MICCAI} 2022},
 doi = {10.1007/978-3-031-16446-0_8},
 editor = {Wang, Linwei and Dou, Qi and Fletcher, P. Thomas and Speidel, Stefanie and Li, Shuo},
 issn = {978-3-031-16446-0},
 organization = {Springer Nature Switzerland},
 pages = {78--87},
 title = {Swin-{VoxelMorph}: A {Symmetric} {Unsupervised} {Learning} {Model} for {Deformable} {Medical} {Image} {Registration} {Using} {Swin} {Transformer}},
 year = {2022}
}
