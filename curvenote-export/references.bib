@article{horwathUnderstandingImportantFeatures2020a,
  note = {[Online; accessed 2024-05-16]},
  author = {Horwath, James P. and Zakharov, Dmitri N. and M{\' e}gret, R{\' e}mi and Stach, Eric A.},
  journal = {npj Computational Materials},
  number = {1},
  year = {2020},
  month = {jul 29},
  pages = {1--9},
  title = {Understanding {Important} {Features} of {Deep} {Learning} {Models} for {Segmentation} of {High}-{Resolution} {Transmission} {Electron} {Microscopy} {Images}},
  volume = {6},
  doi = {10.1038/s41524-020-00363-x},
  issn = {2057-3960},
  url = {https://www.nature.com/articles/s41524-020-00363-x},
}

@article{minaeeImageSegmentationUsing2022,
  note = {[Online; accessed 2024-05-16]},
  author = {Minaee, Shervin and Boykov, Yuri and Porikli, Fatih and Plaza, Antonio and Kehtarnavaz, Nasser and Terzopoulos, Demetri},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  number = {7},
  year = {2022},
  month = {7},
  pages = {3523--3542},
  title = {Image {Segmentation} {Using} {Deep} {Learning}: A {Survey}},
  volume = {44},
  doi = {10.1109/TPAMI.2021.3059968},
  issn = {1939-3539},
  url = {https://ieeexplore.ieee.org/document/9356353},
}

@article{Masubuchi2020Deep,
  author = {Masubuchi, Satoru and Watanabe, Eisuke and Seo, Yuta and Okazaki, Shota and Sasagawa, Takao and Watanabe, Kenji and Taniguchi, Takashi and Machida, Tomoki},
  journal = {npj 2D Materials and Applications},
  number = {1},
  year = {2020},
  month = {mar 23},
  title = {Deep-learning-based image segmentation integrated with optical microscopy for automatically searching for two-dimensional materials},
  volume = {4},
  doi = {10.1038/s41699-020-0137-z},
  issn = {2397-7132},
  url = {http://dx.doi.org/10.1038/s41699-020-0137-z},
}

@book{shapiroComputerVision2001a,
  address = {Upper Saddle River, NJ},
  author = {Shapiro, Linda G. and Stockman, George C.},
  year = {2001},
  publisher = {Prentice Hall},
  title = {Computer {Vision}},
  issn = {978-0-13-030796-5},
}

@inproceedings{senthilkumaranImageSegmentationSurvey2009,
  note = {[Online; accessed 2024-08-02]},
  author = {Senthilkumaran, N. and Rajesh, R.},
  booktitle = {2009 {International} {Conference} on {Advances} in {Recent} {Technologies} in {Communication} and {Computing}},
  year = {2009},
  month = {10},
  pages = {844--846},
  title = {Image {Segmentation} - {A} {Survey} of {Soft} {Computing} {Approaches}},
  doi = {10.1109/ARTCom.2009.219},
  url = {https://ieeexplore.ieee.org/abstract/document/5328277},
}

@article{azimiAdvancedSteelMicrostructural2018,
  note = {[Online; accessed 2024-05-17]},
  author = {Azimi, Seyed Majid and Britz, Dominik and Engstler, Michael and Fritz, Mario and M{\" u}cklich, Frank},
  journal = {Scientific Reports},
  number = {1},
  year = {2018},
  month = {feb 1},
  pages = {2128},
  title = {Advanced {Steel} {Microstructural} {Classification} by {Deep} {Learning} {Methods}},
  volume = {8},
  doi = {10.1038/s41598-018-20037-5},
  issn = {2045-2322},
  url = {https://www.nature.com/articles/s41598-018-20037-5},
}

@misc{solawetzWhatYOLOv8Ultimate2023,
  author = {Solawetz, Jacob and {Francesco}},
  year = {2023},
  month = {jan 11},
  note = {YOLOv8 \textbackslash{}par The \textbf{https://blog.roboflow.com/guide-to-yolo-models/} series of models has become famous in the computer vision world. YOLO's fame is attributable to its considerable accuracy while maintaining a small model size. YOLO models can be trained on a single GPU, which makes it accessible to a wide range of developers. Machine learning practitioners can deploy it for low cost on edge hardware or in the cloud.\textbackslash{}\textbackslash{} YOLO(You Only Look Once) YOLO  YOLO  GPU , \textbackslash{}par YOLOv8 author, Glenn Jocher at Ultralytics, shadowed the \textbf{https://blog.roboflow.com/training-a-yolov3-object-detection-model-with-a-custom-dataset/} (a deep learning framework from Facebook). As the training in the shadow repo got better, Ultralytics eventually launched its own model: \textbf{https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/}.\textbackslash{}\textbackslash{} YOLOv8 ,Ultralytics  Glenn Jocher, PyTorch(Facebook ) YOLOv3 ,Ultralytics :YOLOv5 \textbackslash{}par YOLOv5 quickly became the world's SOTA repo given its flexible Pythonic structure. This structure allowed the community to invent new modeling improvements and quickly share them across repository with similar PyTorch methods.\textbackslash{}\textbackslash{}  Pythonic ,YOLOv5  SOTA , PyTorch  \textbackslash{}par Along with strong model fundamentals, the YOLOv5 maintainers have been committed to supporting a healthy software ecosystem around the model. They actively fix issues and push the capabilities of the repository as the community demands.\textbackslash{}\textbackslash{} ,YOLOv5  \textbackslash{}par In the last two years, various models branched off of the YOLOv5 PyTorch repository, including \textbf{https://roboflow.com/model/scaled-yolov4?ref=blog.roboflow.com}, \textbf{https://blog.roboflow.com/train-yolor-on-a-custom-dataset/}, and \textbf{https://blog.roboflow.com/yolov7-breakdown/}. Other models emerged around the world out of their own PyTorch based implementations, such as \textbf{https://blog.roboflow.com/how-to-train-yolox-on-a-custom-dataset/} and \textbf{https://blog.roboflow.com/how-to-train-yolov6-on-a-custom-dataset/}. Along the way, each YOLO model has brought new SOTA techniques that continue to push the model's accuracy and efficiency.\textbackslash{}\textbackslash{} ,YOLOv5 PyTorch , Scaled-YOLOv4YOLOR  YOLOv7 PyTorch , YOLOX  YOLOv6, YOLO  SOTA , \textbackslash{}par Over the last six months, Ultralytics worked on researching the newest SOTA version of YOLO, YOLOv8. YOLOv8 was launched on January 10th, 2023.\textbackslash{}\textbackslash{} ,Ultralytics  YOLO  SOTA  YOLOv8 YOLOv82023110},
  publisher = {Roboflow Blog},
  title = {What {Is} {YOLOv8}? {The} {Ultimate} {Guide}. [2024]},
  url = {https://blog.roboflow.com/whats-new-in-yolov8/},
}

@article{dosovitskiyIMAGEWORTH16X162021,
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  year = {2021},
  pages = {22},
  title = {AN {IMAGE} {IS} {WORTH} 16X16 {WORDS}: TRANSFORMERS {FOR} {IMAGE} {RECOGNITION} {AT} {SCALE}},
}

@inproceedings{ramezaniAutomatic2DMaterial2023,
  note = {[Online; accessed 2024-05-16]},
  author = {Ramezani, Fereshteh and Parvez, Sheikh and Fix, J. Pierce and Battaglin, Arthur and Whyte, Seamus and Borys, Nicholas J. and Whitaker, Bradley},
  booktitle = {AI and {Optical} {Data} {Sciences} {IV}},
  year = {2023},
  month = {mar 15},
  pages = {316--322},
  organization = {SPIE},
  title = {Automatic 2D {Material} {Detection} in {Optical} {Images} {Using} {Deep}-{Learning}-{Based} {Computer} {Vision}},
  volume = {12438},
  doi = {10.1117/12.2647425},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12438/1243816/Automatic-2D-material-detection-in-optical-images-using-deep-learning/10.1117/12.2647425.full},
}

@misc{caoSwinUnetUnetlikePure2021,
  author = {Cao, Hu and Wang, Yueyue and Chen, Joy and Jiang, Dongsheng and Zhang, Xiaopeng and Tian, Qi and Wang, Manning},
  year = {2021},
  month = {may 12},
  note = {Comment: a drafted manuscript},
  title = {Swin-{Unet}: Unet-like {Pure} {Transformer} for {Medical} {Image} {Segmentation}},
  doi = {10.48550/arXiv.2105.05537},
  url = {http://arxiv.org/abs/2105.05537},
}

@inproceedings{zhangResearchAdvancedImage2022,
  author = {Zhang, Yifan and Deng, Wenqing and Zheng, Kai and Lu, Xiaoyao},
  booktitle = {2022 {International} {Conference} on {Applied} {Physics} and {Computing} ({ICAPC})},
  year = {2022},
  month = {9},
  note = {2},
  pages = {282--289},
  title = {Research {Advanced} in the {Image} {Segmentation}},
  doi = {10.1109/ICAPC57304.2022.00060},
  url = {https://ieeexplore.ieee.org/document/10091316},
}

@article{sterbentzUniversalImageSegmentation2021,
  note = {[Online; accessed 2024-05-18]},
  author = {Sterbentz, Randy M. and Haley, Kristine L. and Island, Joshua O.},
  journal = {Scientific Reports},
  number = {1},
  year = {2021},
  month = {mar 11},
  pages = {5808},
  title = {Universal {Image} {Segmentation} for {Optical} {Identification} of 2D {Materials}},
  volume = {11},
  doi = {10.1038/s41598-021-85159-9},
  issn = {2045-2322},
  url = {https://www.nature.com/articles/s41598-021-85159-9},
}

@article{zhuDeepLearningFrameworkAutomated2022,
  author = {Zhu, Zhiwen and Lu, Jiayi and Zheng, Fengru and Chen, Cheng and Lv, Yang and Jiang, Hao and Yan, Yuyi and Narita, Akimitsu and M{\" u}llen, Klaus and Wang, Xiao-Ye and Sun, Qiang},
  journal = {Angewandte Chemie International Edition},
  number = {49},
  year = {2022},
  note = {2},
  pages = {e202213503},
  title = {A {Deep}-{Learning} {Framework} for the {Automated} {Recognition} of {Molecules} in {Scanning}-{Probe}-{Microscopy} {Images}},
  volume = {61},
  doi = {10.1002/anie.202213503},
  issn = {1521-3773},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.202213503},
}

@inproceedings{nielsenRegionMergingStatistical2003,
  note = {[Online; accessed 2024-05-17]},
  author = {Nielsen, F. and Nock, R.},
  booktitle = {2003 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, 2003. {Proceedings}.},
  year = {2003},
  month = {6},
  pages = {II--19},
  title = {On {Region} {Merging}: The {Statistical} {Soundness} of {Fast} {Sorting}, with {Applications}},
  volume = {2},
  doi = {10.1109/CVPR.2003.1211447},
  url = {https://ieeexplore.ieee.org/document/1211447},
}

@inproceedings{zhuSwinVoxelMorphSymmetricUnsupervised2022,
  address = {Cham},
  author = {Zhu, Yongpei and Lu, Shi},
  booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} -- {MICCAI} 2022},
  editor = {Wang, Linwei and Dou, Qi and Fletcher, P. Thomas and Speidel, Stefanie and Li, Shuo},
  year = {2022},
  pages = {78--87},
  organization = {Springer Nature Switzerland},
  title = {Swin-{VoxelMorph}: A {Symmetric} {Unsupervised} {Learning} {Model} for {Deformable} {Medical} {Image} {Registration} {Using} {Swin} {Transformer}},
  doi = {10.1007/978-3-031-16446-0_8},
  issn = {978-3-031-16446-0},
}

@misc{xiongEfficientSAMLeveragedMasked2023,
  author = {Xiong, Yunyang and Varadarajan, Bala and Wu, Lemeng and Xiang, Xiaoyu and Xiao, Fanyi and Zhu, Chenchen and Dai, Xiaoliang and Wang, Dilin and Sun, Fei and Iandola, Forrest and Krishnamoorthi, Raghuraman and Chandra, Vikas},
  year = {2023},
  month = {dec 1},
  note = {\textbackslash{}sectionEfficientSAMMetaSAM,5% \textbackslash{}par https://mp.weixin.qq.com/s/VqFW2mVan82B2fpcjkQ0Wg},
  title = {EfficientSAM: Leveraged {Masked} {Image} {Pretraining} for {Efficient} {Segment} {Anything}},
  doi = {10.48550/arXiv.2312.00863},
  url = {http://arxiv.org/abs/2312.00863},
}

@article{tobiasImageSegmentationHistogram2002,
  note = {[Online; accessed 2024-08-02]},
  author = {Tobias, O.J. and Seara, R.},
  journal = {IEEE Transactions on Image Processing},
  number = {12},
  year = {2002},
  month = {12},
  pages = {1457--1465},
  title = {Image {Segmentation} by {Histogram} {Thresholding} {Using} {Fuzzy} {Sets}},
  volume = {11},
  doi = {10.1109/TIP.2002.806231},
  issn = {1941-0042},
  url = {https://ieeexplore.ieee.org/abstract/document/1176934},
}

@inproceedings{freixenetAnotherSurveyImage2002,
  address = {Berlin, Heidelberg},
  author = {Freixenet, J. and Mu{\~ n}oz, X. and Raba, D. and Mart{\' i}, J. and Cuf{\' i}, X.},
  booktitle = {Computer {Vision} --- {ECCV} 2002},
  editor = {Heyden, Anders and Sparr, Gunnar and Nielsen, Mads and Johansen, Peter},
  year = {2002},
  pages = {408--422},
  organization = {Springer},
  title = {Yet {Another} {Survey} on {Image} {Segmentation}: Region and {Boundary} {Information} {Integration}},
  doi = {10.1007/3-540-47977-5_27},
  issn = {978-3-540-47977-2},
}

@inproceedings{chuangObjectiveEvaluationSegmentation2010,
  note = {[Online; accessed 2024-05-18]},
  author = {Chuang, Hsiao-Chiang and Comer, Mary L.},
  booktitle = {2010 {IEEE} {Southwest} {Symposium} on {Image} {Analysis} \& {Interpretation} ({SSIAI})},
  year = {2010},
  month = {5},
  pages = {137--140},
  title = {Objective {Evaluation} for {Segmentation} of {Microscope} {Images} of {Materials}},
  doi = {10.1109/SSIAI.2010.5483898},
  url = {https://ieeexplore.ieee.org/document/5483898},
}

@article{lecunGradientbasedLearningApplied1998,
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal = {Proceedings of the IEEE},
  number = {11},
  year = {1998},
  month = {11},
  note = {},
  pages = {2278--2324},
  title = {Gradient-{Based} {Learning} {Applied} to {Document} {Recognition}},
  volume = {86},
  doi = {10.1109/5.726791},
  issn = {1558-2256},
  url = {https://ieeexplore.ieee.org/document/726791},
}

@book{vapnikNatureStatisticalLearning1995,
  address = {New York},
  author = {Vapnik, Vladimir Naumovich},
  year = {1995},
  publisher = {Springer},
  title = {The {Nature} of {Statistical} {Learning} {Theory}},
  issn = {978-0-387-94559-0},
}

@article{ghoshUnderstandingDeepLearning2019,
  author = {Ghosh, Swarnendu and Das, Nibaran and Das, Ishita and Maulik, Ujjwal},
  journal = {ACM Comput. Surv.},
  number = {4},
  year = {2019},
  month = {aug 30},
  note = {{}},
  pages = {73:1--73:35},
  title = {Understanding {Deep} {Learning} {Techniques} for {Image} {Segmentation}},
  volume = {52},
  doi = {10.1145/3329784},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3329784},
}

@article{lecunBackpropagationAppliedHandwritten1989,
  note = {[Online; accessed 2024-05-19]},
  author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  journal = {Neural Computation},
  number = {4},
  year = {1989},
  month = {12},
  pages = {541--551},
  title = {Backpropagation {Applied} to {Handwritten} {Zip} {Code} {Recognition}},
  volume = {1},
  doi = {10.1162/neco.1989.1.4.541},
  issn = {0899-7667},
  url = {https://ieeexplore.ieee.org/abstract/document/6795724},
}

@article{mccullochLogicalCalculusIdeas1943,
  note = {[Online; accessed 2024-05-19]},
  author = {McCulloch, Warren S. and Pitts, Walter},
  journal = {The bulletin of mathematical biophysics},
  number = {4},
  year = {1943},
  month = {dec 1},
  pages = {115--133},
  title = {A {Logical} {Calculus} of the {Ideas} {Immanent} in {Nervous} {Activity}},
  volume = {5},
  doi = {10.1007/BF02478259},
  issn = {1522-9602},
  url = {https://doi.org/10.1007/BF02478259},
}

@article{kramerNonlinearPrincipalComponent1991,
  note = {[Online; accessed 2024-05-19]},
  author = {Kramer, Mark A.},
  journal = {AIChE Journal},
  number = {2},
  year = {1991},
  pages = {233--243},
  title = {Nonlinear {Principal} {Component} {Analysis} {Using} {Autoassociative} {Neural} {Networks}},
  volume = {37},
  doi = {10.1002/aic.690370209},
  issn = {1547-5905},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aic.690370209},
}

@misc{ronnebergerUNetConvolutionalNetworks2015,
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  year = {2015},
  month = {may 18},
  note = {Comment: conditionally accepted at MICCAI 2015},
  title = {U-{Net}: Convolutional {Networks} for {Biomedical} {Image} {Segmentation}},
  doi = {10.48550/arXiv.1505.04597},
  url = {http://arxiv.org/abs/1505.04597},
}

@book{bishopPatternRecognitionMachine2006,
  address = {New York},
  author = {Bishop, Christopher M.},
  series = {Information {Science} and {Statistics}},
  year = {2006},
  publisher = {Springer},
  title = {Pattern {Recognition} and {Machine} {Learning}},
  issn = {978-0-387-31073-2},
}

@article{geDeepLearningAnalysis2020,
  author = {Ge, M. and Su, F. and Zhao, Z. and Su, D.},
  journal = {Materials Today Nano},
  year = {2020},
  month = {aug 1},
  note = {1},
  pages = {100087},
  title = {Deep {Learning} {Analysis} on {Microscopic} {Imaging} in {Materials} {Science}},
  volume = {11},
  doi = {10.1016/j.mtnano.2020.100087},
  issn = {2588-8420},
  url = {https://www.sciencedirect.com/science/article/pii/S258884202030016X},
}

@misc{liuSwinTransformerHierarchical2021,
  author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  year = {2021},
  month = {aug 17},
  note = {Swin Transformer},
  title = {Swin {Transformer}: Hierarchical {Vision} {Transformer} {Using} {Shifted} {Windows}},
  doi = {10.48550/arXiv.2103.14030},
  url = {http://arxiv.org/abs/2103.14030},
}

@misc{liuVisionMambaComprehensive2024,
  author = {Liu, Xiao and Zhang, Chenxu and Zhang, Lei},
  year = {2024},
  month = {may 7},
  note = {Comment: https://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy},
  title = {Vision {Mamba}: A {Comprehensive} {Survey} and {Taxonomy}},
  doi = {10.48550/arXiv.2405.04404},
  url = {http://arxiv.org/abs/2405.04404},
}

@inproceedings{vaswaniAttentionAllYou2017,
  note = {[Online; accessed 2024-04-15]},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L{} and Polosukhin, Illia},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  year = {2017},
  organization = {Curran Associates, Inc.},
  title = {Attention {Is} {All} {You} {Need}},
  volume = {30},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
}

@misc{touvronLLaMAOpenEfficient2023,
  note = {[Online; accessed 2024-05-19]},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\' e}e and Rozi{\` e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  year = {2023},
  month = {feb 27},
  title = {LLaMA: Open and {Efficient} {Foundation} {Language} {Models}},
  doi = {10.48550/arXiv.2302.13971},
  url = {http://arxiv.org/abs/2302.13971},
}

@article{hintonReducingDimensionalityData2006,
  note = {[Online; accessed 2024-05-19]},
  author = {Hinton, G. E. and Salakhutdinov, R. R.},
  journal = {Science},
  number = {5786},
  year = {2006},
  month = {jul 28},
  pages = {504--507},
  title = {Reducing the {Dimensionality} of {Data} with {Neural} {Networks}},
  volume = {313},
  doi = {10.1126/science.1127647},
  url = {https://www.science.org/doi/10.1126/science.1127647},
}

@misc{xuVisualMambaSurvey2024,
  author = {Xu, Rui and Yang, Shu and Wang, Yihui and Cai, Yu and Du, Bo and Chen, Hao},
  year = {2024},
  month = {jul 6},
  note = {Comment: Under Review},
  title = {Visual {Mamba}: A {Survey} and {New} {Outlooks}},
  doi = {10.48550/arXiv.2404.18861},
  url = {http://arxiv.org/abs/2404.18861},
}

@article{congReviewYOLOObject2023,
  author = {Cong, Xiaohan and Li, Shixin and Chen, Fankai and Liu, Chen and Meng, Yue},
  journal = {Frontiers in Computing and Intelligent Systems},
  number = {2},
  year = {2023},
  month = {jun 25},
  note = {YOLO2},
  pages = {17--20},
  title = {A {Review} of {YOLO} {Object} {Detection} {Algorithms} {Based} on {Deep} {Learning}},
  volume = {4},
  doi = {10.54097/fcis.v4i2.9730},
  issn = {2832-6024},
  url = {https://drpress.org/ojs/index.php/fcis/article/view/9730},
}

@misc{guEfficientlyModelingLong2022,
  author = {Gu, Albert and Goel, Karan and R{\' e}, Christopher},
  year = {2022},
  month = {aug 5},
  note = {Comment: ICLR 2022 (Outstanding Paper HM)},
  title = {Efficiently {Modeling} {Long} {Sequences} with {Structured} {State} {Spaces}},
  doi = {10.48550/arXiv.2111.00396},
  url = {http://arxiv.org/abs/2111.00396},
}

@misc{vRealTimeObject2022,
  note = {[Online; accessed 2024-05-16]},
  author = {V, Viswanatha and K, Chandana R. and C., Ramachandra A.},
  year = {2022},
  month = {jul 23},
  title = {Real {Time} {Object} {Detection} {System} with {YOLO} and {CNN} {Models}: A {Review}},
  doi = {10.48550/arXiv.2208.00773},
  url = {http://arxiv.org/abs/2208.00773},
}

@misc{guMambaLinearTimeSequence2023,
  note = {[Online; accessed 2024-05-13]},
  author = {Gu, Albert and Dao, Tri},
  year = {2023},
  month = {dec 1},
  title = {Mamba: Linear-{Time} {Sequence} {Modeling} with {Selective} {State} {Spaces}},
  doi = {10.48550/arXiv.2312.00752},
  url = {http://arxiv.org/abs/2312.00752},
}

@inproceedings{kirillovSegmentAnything2023,
  note = {[Online; accessed 2024-04-15]},
  author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollar, Piotr and Girshick, Ross},
  year = {2023},
  pages = {4015--4026},
  title = {Segment {Anything}},
  url = {https://openaccess.thecvf.com/content/ICCV2023/html/Kirillov_Segment_Anything_ICCV_2023_paper.html},
}

@article{yangDecouplingFeaturesHierarchical2022,
  author = {Yang, Zongxin and Yang, Yi},
  journal = {Advances in Neural Information Processing Systems},
  year = {2022},
  month = {dec 6},
  note = {DeAOT},
  pages = {36324--36336},
  title = {Decoupling {Features} in {Hierarchical} {Propagation} for {Video} {Object} {Segmentation}},
  volume = {35},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/eb890c36af87e4ca82e8ef7bcba6a284-Abstract-Conference.html},
}

@inproceedings{zhangDVISDecoupledVideo2023,
  author = {Zhang, Tao and Tian, Xingye and Wu, Yu and Ji, Shunping and Wang, Xuebo and Zhang, Yuan and Wan, Pengfei},
  year = {2023},
  note = {\textbackslash{}section\&DVIS \textbackslash{}par https://mp.weixin.qq.com/s/VqVuSza2IG7p1l\textunderscore{}RBjt1HQ},
  pages = {1282--1291},
  title = {DVIS: Decoupled {Video} {Instance} {Segmentation} {Framework}},
  url = {https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DVIS_Decoupled_Video_Instance_Segmentation_Framework_ICCV_2023_paper.html},
}

@article{zhangYOLOSeriesTarget2023,
  author = {Zhang, Yuan},
  journal = {Highlights in Science, Engineering and Technology},
  year = {2023},
  month = {apr 1},
  note = {YOLO3},
  pages = {841--847},
  title = {YOLO {Series} {Target} {Detection} {Technology} and {Application}},
  volume = {39},
  doi = {10.54097/hset.v39i.6653},
  issn = {2791-0210},
  url = {https://drpress.org/ojs/index.php/HSET/article/view/6653},
}

@misc{zhangVMUNETV2RethinkingVision2024,
  author = {Zhang, Mingya and Yu, Yue and Gu, Limei and Lin, Tingsheng and Tao, Xianping},
  year = {2024},
  month = {mar 14},
  note = {Comment: 12 pages, 4 figures},
  title = {VM-{UNET}-{V2} {Rethinking} {Vision} {Mamba} {UNet} for {Medical} {Image} {Segmentation}},
  doi = {10.48550/arXiv.2403.09157},
  url = {http://arxiv.org/abs/2403.09157},
}

@misc{liVisualizingLossLandscape2018,
  author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  year = {2018},
  month = {nov 7},
  note = {Comment: NIPS 2018 (extended version, 10.5 pages), code is available at https://github.com/tomgoldstein/loss-landscape},
  title = {Visualizing the {Loss} {Landscape} of {Neural} {Nets}},
  doi = {10.48550/arXiv.1712.09913},
  url = {http://arxiv.org/abs/1712.09913},
}

@misc{chengSegmentTrackAnything2023,
  author = {Cheng, Yangming and Li, Liulei and Xu, Yuanyou and Li, Xiaodi and Yang, Zongxin and Wang, Wenguan and Yang, Yi},
  year = {2023},
  month = {may 11},
  note = {SAM+DeAOTSAM-Track \textbackslash{}par https://mp.weixin.qq.com/s/H5GvPU-JHkL5OwwwUkI9hA},
  title = {Segment and {Track} {Anything}},
  doi = {10.48550/arXiv.2305.06558},
  url = {http://arxiv.org/abs/2305.06558},
}

@misc{zhangSamGuidedEnhancedFineGrained2023,
  author = {Zhang, Zhenyu and Wang, Benlu and Liang, Weijie and Li, Yizhi and Guo, Xuechen and Wang, Guanhong and Li, Shiyan and Wang, Gaoang},
  year = {2023},
  month = {dec 30},
  note = {https://www.youtube.com/watch?v=j2qSVKit4pc},
  title = {Sam-{Guided} {Enhanced} {Fine}-{Grained} {Encoding} with {Mixed} {Semantic} {Learning} for {Medical} {Image} {Captioning}},
  doi = {10.48550/arXiv.2311.01004},
  url = {http://arxiv.org/abs/2311.01004},
}

@article{article,
  author = {Hochreiter, Sepp},
  year = {1991},
  month = {4},
  title = {Untersuchungen zu dynamischen neuronalen {Netzen}},
}

@misc{shuTinySAMPushingEnvelope2024,
  note = {[Online; accessed 2024-05-19]},
  author = {Shu, Han and Li, Wenshuo and Tang, Yehui and Zhang, Yiman and Chen, Yihao and Li, Houqiang and Wang, Yunhe and Chen, Xinghao},
  year = {2024},
  month = {mar 9},
  title = {TinySAM: Pushing the {Envelope} for {Efficient} {Segment} {Anything} {Model}},
  doi = {10.48550/arXiv.2312.13789},
  url = {http://arxiv.org/abs/2312.13789},
}

@misc{yanBridgingGapEndtoend2023,
  author = {Yan, Feng and Luo, Weixin and Zhong, Yujie and Gan, Yiyang and Ma, Lin},
  year = {2023},
  month = {may 22},
  note = {SAM+MOTVISAM},
  title = {Bridging the {Gap} {Between} {End}-to-end and {Non}-{End}-to-end {Multi}-{Object} {Tracking}},
  doi = {10.48550/arXiv.2305.12724},
  url = {http://arxiv.org/abs/2305.12724},
}

@misc{zhangFasterSegmentAnything2023,
  author = {Zhang, Chaoning and Han, Dongshen and Qiao, Yu and Kim, Jung Uk and Bae, Sung-Ho and Lee, Seungkyu and Hong, Choong Seon},
  year = {2023},
  month = {jul 1},
  note = {Comment: First work to make SAM lightweight for mobile applications},
  title = {Faster {Segment} {Anything}: Towards {Lightweight} {SAM} for {Mobile} {Applications}},
  doi = {10.48550/arXiv.2306.14289},
  url = {http://arxiv.org/abs/2306.14289},
}

@misc{yangTrackAnythingSegment2023,
  author = {Yang, Jinyu and Gao, Mingqi and Li, Zhe and Gao, Shang and Wang, Fangjing and Zheng, Feng},
  year = {2023},
  month = {apr 27},
  note = { \textbackslash{}par Track Anything Model, TAMSegment Anything Model, SAM,SAM ,SAM ,\textbf{}TAM,,,, \textbackslash{}par \textbackslash{}sectionSAM+VOSTrack-Anything \textbackslash{}par https://mp.weixin.qq.com/s/Q4X3pUP07QM2TdvVE\textunderscore{}WRYg},
  title = {Track {Anything}: Segment {Anything} {Meets} {Videos}},
  doi = {10.48550/arXiv.2304.11968},
  url = {http://arxiv.org/abs/2304.11968},
}

@misc{laiLISAReasoningSegmentation2024,
  author = {Lai, Xin and Tian, Zhuotao and Chen, Yukang and Li, Yanwei and Yuan, Yuhui and Liu, Shu and Jia, Jiaya},
  year = {2024},
  month = {may 1},
  note = {Comment: Code, models, and data are available at https://github.com/dvlab-research/LISA},
  title = {LISA: Reasoning {Segmentation} via {Large} {Language} {Model}},
  doi = {10.48550/arXiv.2308.00692},
  url = {http://arxiv.org/abs/2308.00692},
}

@misc{zhaoFastSegmentAnything2023,
  author = {Zhao, Xu and Ding, Wenchao and An, Yongqi and Du, Yinglong and Yu, Tao and Li, Min and Tang, Ming and Wang, Jinqiao},
  year = {2023},
  month = {jun 21},
  note = {Comment: Technical Report. The code is released at https://github.com/CASIA-IVA-Lab/FastSAM},
  title = {Fast {Segment} {Anything}},
  doi = {10.48550/arXiv.2306.12156},
  url = {http://arxiv.org/abs/2306.12156},
}

@misc{baiMaskedAutoencodersEnable2022,
  author = {Bai, Yutong and Wang, Zeyu and Xiao, Junfei and Wei, Chen and Wang, Huiyu and Yuille, Alan and Zhou, Yuyin and Xie, Cihang},
  year = {2022},
  month = {nov 9},
  note = {Masked Distillers [EfficientSAM]},
  title = {Masked {Autoencoders} {Enable} {Efficient} {Knowledge} {Distillers}},
  doi = {10.48550/arXiv.2208.12256},
  url = {http://arxiv.org/abs/2208.12256},
}

@misc{xuLongShortTermTransformer2021,
  author = {Xu, Mingze and Xiong, Yuanjun and Chen, Hao and Li, Xinyu and Xia, Wei and Tu, Zhuowen and Soatto, Stefano},
  year = {2021},
  month = {dec 22},
  note = {Comment: NeurIPS 2021 Spotlight},
  title = {Long {Short}-{Term} {Transformer} for {Online} {Action} {Detection}},
  doi = {10.48550/arXiv.2107.03377},
  url = {http://arxiv.org/abs/2107.03377},
}

@misc{songSAMLighteningLightweightSegment2024,
  note = {[Online; accessed 2024-05-19]},
  author = {Song, Yanfei and Pu, Bangzheng and Wang, Peng and Jiang, Hongxu and Dong, Dong and Cao, Yongxiang and Shen, Yiqing},
  year = {2024},
  month = {mar 17},
  title = {SAM-{Lightening}: A {Lightweight} {Segment} {Anything} {Model} with {Dilated} {Flash} {Attention} to {Achieve} 30 {Times} {Acceleration}},
  doi = {10.48550/arXiv.2403.09195},
  url = {http://arxiv.org/abs/2403.09195},
}

@misc{heMaskedAutoencodersAre2021,
  author = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\' a}r, Piotr and Girshick, Ross},
  year = {2021},
  month = {dec 19},
  note = {Masked Autoencoders [EfficientSAM]},
  title = {Masked {Autoencoders} {Are} {Scalable} {Vision} {Learners}},
  doi = {10.48550/arXiv.2111.06377},
  url = {http://arxiv.org/abs/2111.06377},
}
